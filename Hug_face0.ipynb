{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyM/njpDiBQ+tR4FF10uQYn/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshalzate/1_Real_Estate_Data_Science_Application/blob/main/Hug_face0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggKnYo08WfsU"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "zlgw298LWjQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"stanfordnlp/imdb\")"
      ],
      "metadata": {
        "id": "R2DshmKLWy6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "ygP_hjQeXK2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'].column_names"
      ],
      "metadata": {
        "id": "mSK6u9IhXPyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'].features['label'].names"
      ],
      "metadata": {
        "id": "r6uvBDk0Xthr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'].num_rows"
      ],
      "metadata": {
        "id": "6FoHO77qXz_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'].shape"
      ],
      "metadata": {
        "id": "veoTPLFuYATx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'].num_columns"
      ],
      "metadata": {
        "id": "Ihzg01eYYEmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'].shuffle()"
      ],
      "metadata": {
        "id": "oCjc5w9eYTSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.shuffle()"
      ],
      "metadata": {
        "id": "N9BuR4aVYH7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'].select(range(100)).filter(lambda x: len(x['text'])>10).train_test_split(test_size = 0.8)"
      ],
      "metadata": {
        "id": "fJ7FpCKgYQqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "big_data = load_dataset(\"openwebtext\", streaming=True)"
      ],
      "metadata": {
        "id": "nwq_HmMKYh1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# custome dataset\n",
        "from datasets import Dataset\n",
        "data = {\"text\": [\n",
        "        \"I love this product! Works great \",\n",
        "        \"Terrible experience, I want a refund.\",\n",
        "        \"Fast delivery and excellent packaging.\",\n",
        "        \"Worst app Iâ€™ve ever used. Crashed in 1 minute.\",\n",
        "        \"Super helpful support team, thanks a lot!\",\n",
        "        \"Nothing worked. Waste of time.\"\n",
        "    ],\n",
        "    \"label\": [1, 0, 1, 0, 1, 0] }\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(data)\n",
        "dataset_new = Dataset.from_pandas(df)\n",
        "dataset_new"
      ],
      "metadata": {
        "id": "rML7gsH4ZcZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_new.class_encode_column('label')['label']"
      ],
      "metadata": {
        "id": "PCq15gW-Z-bG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "Ez9jOzdDajP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel"
      ],
      "metadata": {
        "id": "5kc8QwpQbUOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased',use_fast = True)"
      ],
      "metadata": {
        "id": "U3IylF81bsQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.tokenize(\"harhal is stoic\")"
      ],
      "metadata": {
        "id": "iHTMG7rVcPw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token = tokenizer(\"harhal is stoic\", padding = \"max_length\", truncation = True)"
      ],
      "metadata": {
        "id": "eMVFywn5cxUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text):\n",
        "  return tokenizer(text['text'],padding = 'max_length', truncation = True,return_tensors= 'pt')"
      ],
      "metadata": {
        "id": "IvDqNn9qcz20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_new = dataset_new.map(tokenize,batched = True)"
      ],
      "metadata": {
        "id": "ij2TNiB8deH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_new['input_ids']"
      ],
      "metadata": {
        "id": "RrZcFdqde0Ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.from_pretrained(\"ai4bharat/indic-bert\")"
      ],
      "metadata": {
        "id": "dV7OS8ike4s3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training your own tokenizer\n",
        "from tokenizers import Tokenizer, models, trainers, pre_tokenizers"
      ],
      "metadata": {
        "id": "NB-PRdoOljCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\"I love transformers!\", \"Tokenizers are amazing.\", \"Build your own.\\n\"]"
      ],
      "metadata": {
        "id": "aPv803t6muAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(models.BPE())"
      ],
      "metadata": {
        "id": "0eJPRIgzpm9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()"
      ],
      "metadata": {
        "id": "qPh0seS3pzx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = trainers.BpeTrainer(vocab_size=1000)"
      ],
      "metadata": {
        "id": "4XBSIxbAp9R8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.train_from_iterator(corpus,trainer)"
      ],
      "metadata": {
        "id": "MXhBISyYqMnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.save('custom-tokenizer.json')"
      ],
      "metadata": {
        "id": "fQtd9Lgiqci2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#one more time"
      ],
      "metadata": {
        "id": "TjkBnEhzqkt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import Tokenizer, models, trainers, pre_tokenizers"
      ],
      "metadata": {
        "id": "2HG0Ud2oqphn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cust_token = Tokenizer(models.BPE())"
      ],
      "metadata": {
        "id": "KzDjbL6tqwEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cust_token.pre_tokenizer = pre_tokenizers.Whitespace()"
      ],
      "metadata": {
        "id": "JqAn5tbHrA7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = trainers.BpeTrainer(vocab_size= 1000)"
      ],
      "metadata": {
        "id": "ONVS2fhKrKSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.train_from_iterator(corpus, trainer)"
      ],
      "metadata": {
        "id": "HapUvNadrlwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.save('custom-tokenizer.json')"
      ],
      "metadata": {
        "id": "WDWsI6tlrsba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's make it fast"
      ],
      "metadata": {
        "id": "9iMdivdnrwpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import PreTrainedTokenizerFast"
      ],
      "metadata": {
        "id": "UFtYnCWKr9Nn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fast_cust_tokenizer = PreTrainedTokenizerFast(\n",
        "    tokenizer_file=\"/content/custom-tokenizer.json\",\n",
        "    unk_token=\"[UNK]\",\n",
        "    pad_token=\"[PAD]\",\n",
        "    cls_token=\"[CLS]\",\n",
        "    sep_token=\"[SEP]\",\n",
        "    mask_token=\"[MASK]\"\n",
        ")"
      ],
      "metadata": {
        "id": "DXGoJkqXsKpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fast_cust_tokenizer.save_pretrained('fast_cust_tokenizer')"
      ],
      "metadata": {
        "id": "17WO0QilsV3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oGNRIDeWsmcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel"
      ],
      "metadata": {
        "id": "vyHnuUThssxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('/content/fast_cust_tokenizer')"
      ],
      "metadata": {
        "id": "G6-8CsEVs5qS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's do the main thing now load the model and use it for prediciton\n",
        "from transformers import AutoTokenizer, AutoModel"
      ],
      "metadata": {
        "id": "exnIanA3tEYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall transformers\n",
        "!pip install transformers --upgrade"
      ],
      "metadata": {
        "id": "C-Nh7lBPvfeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
        "model     = AutoModel.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "id": "chklckX0t4Px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Harshal is the stoic BMF\"\n",
        "tokenized_text = tokenizer(text,padding= 'max_length', truncation = True, return_tensors='pt')"
      ],
      "metadata": {
        "id": "chnlyLC-uXMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "with torch.no_grad():\n",
        "  output = model(**tokenized_text)"
      ],
      "metadata": {
        "id": "k14U-TY6xklE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "id": "n9jHlov-xx9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sentense transformer"
      ],
      "metadata": {
        "id": "2QBYLjlUyZ85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U sentence-transformers"
      ],
      "metadata": {
        "id": "5XLgX5kZVQmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from torch.nn.functional import cosine_similarity"
      ],
      "metadata": {
        "id": "-zvhS0ArVYFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "sent1= \"Harshal is stoic\"\n",
        "sent2 = \"Cricket is popular in india\"\n",
        "embed1 = model.encode(sent1,convert_to_tensor=True)\n",
        "embed2 = model.encode(sent2, convert_to_tensor=True)\n",
        "cosine_similarity(embed1,embed2,dim=0)"
      ],
      "metadata": {
        "id": "nv7Htc3KVxLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VLHfCJ91WQgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hGIWK8DNWzdG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}